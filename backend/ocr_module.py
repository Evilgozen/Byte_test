# -*- coding: utf-8 -*-
"""
OCRè¯†åˆ«æ¨¡å—
è´Ÿè´£è§†é¢‘å¸§çš„OCRè¯†åˆ«ã€å…³é”®è¯åˆ†æç­‰åŠŸèƒ½
"""

from fastapi import HTTPException, Depends
from sqlalchemy.orm import Session
from models_simple import Video, VideoFrame, OCRResult, StageConfig, ProcessStatus
from pathlib import Path
from typing import List, Optional, Dict, Any
from pydantic import BaseModel
from datetime import datetime
from paddleocr import PaddleOCR, TextRecognition
from config import OCRConfig
import json
import os
import time
import cv2


class OCRProcessRequest(BaseModel):
    use_gpu: Optional[bool] = False
    lang: Optional[str] = "ch"  # è¯­è¨€ï¼šch, enç­‰


class OCRResultResponse(BaseModel):
    id: int
    frame_id: int
    text_content: Optional[str]
    confidence: Optional[float]
    bbox: Optional[str]  # Store as JSON string to avoid serialization issues
    processed_at: datetime
    
    class Config:
        from_attributes = True


class EnhancedOCRResultResponse(BaseModel):
    """å¢å¼ºçš„OCRç»“æœå“åº”æ¨¡å‹ - æ”¯æŒPP-OCRv5"""
    frame_id: int
    frame_path: str
    ocr_version: str
    processing_time: float
    text_blocks: List[Dict[str, Any]]
    full_text: str
    total_confidence: float
    text_count: int
    language: str
    image_info: Dict[str, Any]
    detection_results: List[Dict[str, Any]]
    recognition_results: List[Dict[str, Any]]
    raw_result: Optional[List[Dict[str, Any]]] = None
    
    class Config:
        from_attributes = True


class KeywordAnalysisRequest(BaseModel):
    keywords: List[str]
    analysis_type: Optional[str] = "appearance"  # appearance, disappearance, both


class KeywordAnalysisResponse(BaseModel):
    keyword: str
    first_appearance_timestamp: Optional[int]
    first_disappearance_timestamp: Optional[int]
    total_occurrences: int
    frame_occurrences: List[dict]


class OCRProcessor:
    """OCRå¤„ç†å™¨"""
    
    def __init__(self):
        self.ocr_instance = None
        self.ocr_results_path = "./data/ocr_results"
        self.ocr_images_path = "./data/ocr_images"  # æ–°å¢OCRå›¾ç‰‡å­˜å‚¨è·¯å¾„
        
        # ç¡®ä¿OCRç»“æœå­˜å‚¨ç›®å½•å­˜åœ¨
        Path(self.ocr_results_path).mkdir(parents=True, exist_ok=True)
        Path(self.ocr_images_path).mkdir(parents=True, exist_ok=True)  # åˆ›å»ºOCRå›¾ç‰‡ç›®å½•
        
        # åˆå§‹åŒ–OCRå®ä¾‹
        self.initialize_ocr()
    
    def initialize_ocr(self, use_gpu: bool = False, lang: str = "ch") -> None:
        """åˆå§‹åŒ–OCRå®ä¾‹ - ä½¿ç”¨ç”¨æˆ·æ¨èçš„PaddleOCRé…ç½®"""
        try:
            # ä½¿ç”¨ç”¨æˆ·æ¨èçš„PaddleOCRé…ç½®å‚æ•°
            self.ocr_instance = PaddleOCR(
                use_doc_orientation_classify=False,  # ä¸ä½¿ç”¨æ–‡æ¡£æ–¹å‘åˆ†ç±»æ¨¡å‹
                use_doc_unwarping=False,  # ä¸ä½¿ç”¨æ–‡æœ¬å›¾åƒçŸ«æ­£æ¨¡å‹
                use_textline_orientation=False,  # ä¸ä½¿ç”¨æ–‡æœ¬è¡Œæ–¹å‘åˆ†ç±»æ¨¡å‹
                lang=lang,  # è¯­è¨€è®¾ç½®
                use_gpu=use_gpu,  # GPUè®¾ç½®
                show_log=False  # å‡å°‘æ—¥å¿—è¾“å‡º
            )
            print("âœ“ PaddleOCRé…ç½®åˆå§‹åŒ–æˆåŠŸï¼ˆä½¿ç”¨æ¨èé…ç½®ï¼‰")
            
        except Exception as e:
            print(f"âš  OCRåˆå§‹åŒ–å¤±è´¥: {e}")
            # æœ€åŸºæœ¬çš„é…ç½®ä½œä¸ºå¤‡é€‰
            try:
                self.ocr_instance = PaddleOCR(
                    use_angle_cls=True, 
                    lang=lang
                )
                print("âœ“ ä½¿ç”¨åŸºç¡€PaddleOCRé…ç½®")
            except Exception as fallback_e:
                print(f"âš  åŸºç¡€é…ç½®ä¹Ÿå¤±è´¥: {fallback_e}")
                raise ValueError(f"OCRåˆå§‹åŒ–å®Œå…¨å¤±è´¥: {fallback_e}")
    
    def process_frame_ocr(self, frame_path: str, frame_id: int, video_id: int = None, use_gpu: bool = False, lang: str = 'ch', save_raw_result: bool = True) -> dict:
        """å¯¹å•ä¸ªå¸§è¿›è¡ŒOCRè¯†åˆ«"""
        if not self.ocr_instance:
            raise ValueError("OCRå®ä¾‹æœªåˆå§‹åŒ–")
        
        if not os.path.exists(frame_path):
            raise ValueError(f"å¸§å›¾ç‰‡æ–‡ä»¶ä¸å­˜åœ¨: {frame_path}")
        
        try:
            # è·å–å›¾åƒä¿¡æ¯
            image = cv2.imread(frame_path)
            if image is None:
                print(f"âš  æ— æ³•è¯»å–å›¾åƒæ–‡ä»¶: {frame_path}")
                raise ValueError(f"æ— æ³•è¯»å–å›¾åƒæ–‡ä»¶: {frame_path}")
            
            image_height, image_width = image.shape[:2]
            image_channels = image.shape[2] if len(image.shape) > 2 else None
            print(f"ğŸ“· å›¾åƒä¿¡æ¯: {image_width}x{image_height}, é€šé“æ•°: {image_channels}")
            
            # è®°å½•å¤„ç†å¼€å§‹æ—¶é—´
            start_time = time.time()
            
            # æ‰§è¡ŒOCRè¯†åˆ« - ä½¿ç”¨æ–°ç‰ˆpredict API
            print(f"ğŸ” å¼€å§‹OCRè¯†åˆ«: {frame_path}")
            
            # å°è¯•ä½¿ç”¨æ–°ç‰ˆpredict API
            try:
                result = self.ocr_instance.predict(frame_path)
                print(f"ğŸ“ OCRåŸå§‹ç»“æœï¼ˆæ–°ç‰ˆAPIï¼‰: {result}")
                
                # ä¿å­˜OCRå¤„ç†åçš„å›¾ç‰‡
                if video_id is not None:
                    ocr_image_dir = Path(f"{self.ocr_images_path}/video_{video_id}")
                    ocr_image_dir.mkdir(parents=True, exist_ok=True)
                    
                    # ä¿å­˜OCRç»“æœå›¾ç‰‡ï¼ˆä½¿ç”¨æŒ‡å®šæ ¼å¼ï¼‰
                    for res in result:
                        # ç›´æ¥ä¿å­˜ä¸ºæŒ‡å®šæ ¼å¼çš„æ–‡ä»¶å
                        ocr_image_name = f"frame_{frame_id:06d}_333ms_ocr_res_img.jpg"
                        ocr_image_path = ocr_image_dir / ocr_image_name
                        res.save_to_img(save_path=str(ocr_image_path))
                        print(f"âœ… OCRå›¾ç‰‡å·²ä¿å­˜: {ocr_image_path}")
                    
                    # ä¿å­˜åŸå§‹OCRç»“æœåˆ°JSONæ–‡ä»¶ï¼ˆå¦‚æœéœ€è¦ï¼‰
                    if save_raw_result:
                        raw_result_dir = Path(f"{self.ocr_results_path}/video_{video_id}")
                        raw_result_dir.mkdir(parents=True, exist_ok=True)
                        raw_json_name = f"frame_{frame_id:06d}_333ms_ocr_res.json"
                        raw_result_path = raw_result_dir / raw_json_name
                        
                        # å°†åŸå§‹ç»“æœè½¬æ¢ä¸ºå¯åºåˆ—åŒ–çš„æ ¼å¼
                        raw_data = {
                            "frame_id": frame_id,
                            "frame_path": frame_path,
                            "ocr_version": "PP-OCRv5",
                            "processing_time": round(time.time() - start_time, 3),
                            "raw_result": self._serialize_ocr_result(result)
                        }
                        
                        with open(raw_result_path, 'w', encoding='utf-8') as f:
                            json.dump(raw_data, f, ensure_ascii=False, indent=2, default=str)
                        print(f"âœ… åŸå§‹OCRç»“æœå·²ä¿å­˜: {raw_result_path}")
                else:
                    print("âš  æœªæä¾›video_idï¼Œè·³è¿‡OCRå›¾ç‰‡ä¿å­˜")
                
                # è½¬æ¢æ–°ç‰ˆAPIç»“æœä¸ºæ—§ç‰ˆæ ¼å¼ä»¥ä¿æŒå…¼å®¹æ€§
                result = self._convert_new_api_result_to_old_format(result)
                
            except Exception as new_api_error:
                print(f"âš  æ–°ç‰ˆAPIå¤±è´¥ï¼Œå°è¯•æ—§ç‰ˆAPI: {new_api_error}")
                # å›é€€åˆ°æ—§ç‰ˆAPI
                result = self.ocr_instance.ocr(frame_path)
                print(f"ğŸ“ OCRåŸå§‹ç»“æœï¼ˆæ—§ç‰ˆAPIï¼‰: {result}")
            
            # è®¡ç®—å¤„ç†æ—¶é—´
            processing_time = time.time() - start_time
            
            # å¤„ç†OCRç»“æœ - å¢å¼ºçš„JSONç»“æ„
            ocr_data = {
                "frame_id": frame_id,
                "frame_path": frame_path,
                "ocr_version": "PP-OCRv5",
                "processing_time": round(processing_time, 3),
                "text_blocks": [],
                "full_text": "",
                "total_confidence": 0.0,
                "text_count": 0,
                "language": lang,
                "image_info": {
                    "width": image_width,
                    "height": image_height,
                    "channels": image_channels
                },
                "detection_results": [],
                "recognition_results": []
            }
            
            # å¤„ç†ä¸åŒæ ¼å¼çš„OCRç»“æœ
            if result:
                text_blocks = []
                confidences = []
                full_text_parts = []
                detection_results = []
                recognition_results = []
                
                # æ£€æŸ¥æ˜¯å¦æ˜¯æ–°ç‰ˆTextRecognition APIçš„ç»“æœæ ¼å¼
                if isinstance(result, list) and len(result) > 0 and isinstance(result[0], dict):
                    # æ–°ç‰ˆAPIæ ¼å¼å¤„ç†
                    result_dict = result[0]
                    if 'rec_texts' in result_dict and 'rec_scores' in result_dict:
                        rec_texts = result_dict['rec_texts']
                        rec_scores = result_dict['rec_scores']
                        
                        for idx, (text, score) in enumerate(zip(rec_texts, rec_scores)):
                            if text.strip():  # åªå¤„ç†éç©ºæ–‡æœ¬
                                # æ¨¡æ‹Ÿè¾¹ç•Œæ¡†ï¼ˆæ–°ç‰ˆAPIå¯èƒ½ä¸æä¾›è¯¦ç»†åæ ‡ï¼‰
                                bbox = [[0, idx*20], [100, idx*20], [100, (idx+1)*20], [0, (idx+1)*20]]
                                
                                text_block = {
                                    "id": idx,
                                    "text": text,
                                    "confidence": float(score),
                                    "bbox": bbox,
                                    "bbox_normalized": {
                                        "x1": 0,
                                        "y1": idx*20,
                                        "x2": 100,
                                        "y2": (idx+1)*20
                                    },
                                    "text_length": len(text),
                                    "word_count": len(text.split()) if text.strip() else 0
                                }
                                
                                detection_result = {
                                    "id": idx,
                                    "bbox": bbox,
                                    "confidence": float(score)
                                }
                                
                                recognition_result = {
                                    "id": idx,
                                    "text": text,
                                    "confidence": float(score)
                                }
                                
                                text_blocks.append(text_block)
                                detection_results.append(detection_result)
                                recognition_results.append(recognition_result)
                                confidences.append(float(score))
                                full_text_parts.append(text)
                elif isinstance(result, list) and len(result) > 0 and isinstance(result[0], list):
                     # æ—§ç‰ˆAPIæ ¼å¼å¤„ç†
                     for idx, line in enumerate(result[0]):
                         if len(line) >= 2:
                             bbox = line[0]  # è¾¹ç•Œæ¡†åæ ‡
                             text_info = line[1]  # æ–‡æœ¬å’Œç½®ä¿¡åº¦
                             
                             if isinstance(text_info, (list, tuple)) and len(text_info) >= 2:
                                 text = text_info[0]
                                 confidence = float(text_info[1])
                                 
                                 # è¯¦ç»†çš„æ–‡æœ¬å—ä¿¡æ¯
                                 text_block = {
                                     "id": idx,
                                     "text": text,
                                     "confidence": confidence,
                                     "bbox": bbox,
                                     "bbox_normalized": {
                                         "x1": min([point[0] for point in bbox]),
                                         "y1": min([point[1] for point in bbox]),
                                         "x2": max([point[0] for point in bbox]),
                                         "y2": max([point[1] for point in bbox])
                                     },
                                     "text_length": len(text),
                                     "word_count": len(text.split()) if text.strip() else 0
                                 }
                                 
                                 # æ£€æµ‹ç»“æœ
                                 detection_result = {
                                     "id": idx,
                                     "bbox": bbox,
                                     "confidence": confidence
                                 }
                                 
                                 # è¯†åˆ«ç»“æœ
                                 recognition_result = {
                                     "id": idx,
                                     "text": text,
                                     "confidence": confidence,
                                     "char_confidences": []  # å¯ä»¥æ‰©å±•ä¸ºå­—ç¬¦çº§ç½®ä¿¡åº¦
                                 }
                                 
                                 text_blocks.append(text_block)
                                 detection_results.append(detection_result)
                                 recognition_results.append(recognition_result)
                                 confidences.append(confidence)
                                 full_text_parts.append(text)
                
                ocr_data["text_blocks"] = text_blocks
                ocr_data["detection_results"] = detection_results
                ocr_data["recognition_results"] = recognition_results
                ocr_data["full_text"] = " ".join(full_text_parts)
                ocr_data["total_confidence"] = sum(confidences) / len(confidences) if confidences else 0.0
                ocr_data["text_count"] = len(text_blocks)
            
            return ocr_data
            
        except Exception as e:
            raise ValueError(f"OCRå¤„ç†å¤±è´¥: {str(e)}")
    
    def _convert_new_api_result_to_old_format(self, output):
        """è½¬æ¢æ–°ç‰ˆpredict APIç»“æœä¸ºæ—§ç‰ˆocræ ¼å¼"""
        try:
            converted_result = []
            
            for res in output:
                # æ–°ç‰ˆAPIè¿”å›çš„ç»“æœå¯¹è±¡ï¼Œéœ€è¦æå–æ–‡æœ¬å’Œç½®ä¿¡åº¦ä¿¡æ¯
                if hasattr(res, 'rec_texts') and hasattr(res, 'rec_scores'):
                    # å¦‚æœæœ‰rec_textså’Œrec_scoreså±æ€§
                    for text, score in zip(res.rec_texts, res.rec_scores):
                        if text.strip():  # åªå¤„ç†éç©ºæ–‡æœ¬
                            # æ¨¡æ‹Ÿè¾¹ç•Œæ¡†åæ ‡
                            bbox = [[0, 0], [100, 0], [100, 30], [0, 30]]
                            converted_result.append([bbox, [text, float(score)]])
                elif hasattr(res, 'text') and hasattr(res, 'confidence'):
                    # å¦‚æœæœ‰textå’Œconfidenceå±æ€§
                    bbox = [[0, 0], [100, 0], [100, 30], [0, 30]]
                    converted_result.append([bbox, [res.text, float(res.confidence)]])
                else:
                    # å°è¯•å…¶ä»–å¯èƒ½çš„å±æ€§ç»“æ„
                    print(f"âš  æœªçŸ¥çš„ç»“æœæ ¼å¼: {type(res)}, å±æ€§: {dir(res)}")
            
            return [converted_result] if converted_result else [[]]
            
        except Exception as e:
            print(f"æ–°ç‰ˆAPIç»“æœè½¬æ¢å¤±è´¥: {e}")
            return [[]]
    
    def _convert_new_api_result(self, output, frame_path: str):
        """è½¬æ¢æ–°ç‰ˆAPIç»“æœä¸ºæ—§ç‰ˆæ ¼å¼ï¼ˆä¿ç•™åŸæ–¹æ³•ä»¥å…¼å®¹ï¼‰"""
        return self._convert_new_api_result_to_old_format(output)
    
    def _serialize_ocr_result(self, result):
        """å°†OCRç»“æœåºåˆ—åŒ–ä¸ºå¯ä¿å­˜çš„æ ¼å¼"""
        try:
            serialized_result = []
            
            for res in result:
                if hasattr(res, '__dict__'):
                    # å¦‚æœæ˜¯å¯¹è±¡ï¼Œå°è¯•æå–æ‰€æœ‰å±æ€§
                    res_dict = {}
                    for attr_name in dir(res):
                        if not attr_name.startswith('_'):  # è·³è¿‡ç§æœ‰å±æ€§
                            try:
                                attr_value = getattr(res, attr_name)
                                if not callable(attr_value):  # è·³è¿‡æ–¹æ³•
                                    # å¤„ç†numpyæ•°ç»„
                                    if hasattr(attr_value, 'tolist'):
                                        res_dict[attr_name] = attr_value.tolist()
                                    else:
                                        res_dict[attr_name] = attr_value
                            except Exception:
                                continue
                    serialized_result.append(res_dict)
                else:
                    # å¦‚æœæ˜¯åŸºæœ¬ç±»å‹æˆ–åˆ—è¡¨ï¼Œç›´æ¥å¤„ç†
                    if hasattr(res, 'tolist'):
                        serialized_result.append(res.tolist())
                    else:
                        serialized_result.append(res)
            
            return serialized_result
            
        except Exception as e:
            print(f"åºåˆ—åŒ–OCRç»“æœå¤±è´¥: {e}")
            return str(result)  # å›é€€åˆ°å­—ç¬¦ä¸²è¡¨ç¤º
    
    def save_ocr_result_to_file(self, video_id: int, frame_number: int, ocr_data: dict) -> str:
        """ä¿å­˜OCRç»“æœåˆ°JSONæ–‡ä»¶"""
        ocr_output_dir = Path(f"{self.ocr_results_path}/video_{video_id}")
        ocr_output_dir.mkdir(parents=True, exist_ok=True)
        
        ocr_json_path = ocr_output_dir / f"frame_{frame_number}_ocr.json"
        with open(ocr_json_path, 'w', encoding='utf-8') as f:
            json.dump(ocr_data, f, ensure_ascii=False, indent=2)
        
        return str(ocr_json_path)
    
    async def process_video_ocr(self, video_id: int, request: OCRProcessRequest, db: Session) -> dict:
        """å¯¹è§†é¢‘çš„æ‰€æœ‰å¸§è¿›è¡ŒOCRå¤„ç†"""
        # æ£€æŸ¥è§†é¢‘æ˜¯å¦å­˜åœ¨
        video = db.query(Video).filter(Video.id == video_id).first()
        if not video:
            raise HTTPException(status_code=404, detail="è§†é¢‘ä¸å­˜åœ¨")
        
        # è·å–è§†é¢‘çš„æ‰€æœ‰å¸§
        frames = db.query(VideoFrame).filter(VideoFrame.video_id == video_id).order_by(VideoFrame.frame_number).all()
        if not frames:
            raise HTTPException(status_code=404, detail="è§†é¢‘å¸§ä¸å­˜åœ¨ï¼Œè¯·å…ˆè¿›è¡Œåˆ†å¸§å¤„ç†")
        
        try:
            # æ›´æ–°è§†é¢‘çŠ¶æ€ä¸ºå¤„ç†ä¸­
            video.process_status = ProcessStatus.processing
            db.commit()
            
            processed_frames = 0
            failed_frames = 0
            ocr_results = []
            
            for frame in frames:
                try:
                    print(f"ğŸ¬ å¤„ç†å¸§: {frame.id}, è·¯å¾„: {frame.frame_path}")
                    
                    # æ£€æŸ¥æ˜¯å¦å·²ç»å¤„ç†è¿‡OCR
                    existing_ocr = db.query(OCRResult).filter(OCRResult.frame_id == frame.id).first()
                    if existing_ocr:
                        print(f"â­ è·³è¿‡å·²å¤„ç†çš„å¸§: {frame.id}")
                        continue
                    
                    # å¤„ç†OCR
                    print(f"ğŸ” å¼€å§‹å¤„ç†å¸§ {frame.id} çš„OCR")
                    ocr_data = self.process_frame_ocr(frame.frame_path, frame.id, video_id, request.use_gpu, request.lang, save_raw_result=True)
                    print(f"âœ… å¸§ {frame.id} OCRå¤„ç†å®Œæˆï¼Œæ–‡æœ¬æ•°é‡: {ocr_data.get('text_count', 0)}")
                    
                    # ä»JSONæ–‡ä»¶ä¸­æå–rec_textsæ•°ç»„
                    rec_texts = []
                    try:
                        # è¯»å–ä¿å­˜çš„JSONæ–‡ä»¶è·å–rec_texts
                        json_file_path = f"data/ocr_results/video_{video_id}/frame_{frame.id:06d}_333ms_ocr_res.json"
                        if os.path.exists(json_file_path):
                            with open(json_file_path, 'r', encoding='utf-8') as f:
                                json_data = json.load(f)
                                if 'raw_result' in json_data and json_data['raw_result']:
                                    for raw_item in json_data['raw_result']:
                                        if isinstance(raw_item, dict) and 'json' in raw_item:
                                            json_res = raw_item['json']
                                            if isinstance(json_res, dict) and 'res' in json_res:
                                                res_data = json_res['res']
                                                if isinstance(res_data, dict) and 'rec_texts' in res_data:
                                                    rec_texts = res_data['rec_texts']
                                                    break
                    except Exception as e:
                        print(f"è¯»å–rec_textså¤±è´¥: {e}")
                        rec_texts = []
                    
                    # å¦‚æœæ²¡æœ‰æ‰¾åˆ°rec_textsï¼Œä½¿ç”¨å¤‡ç”¨æ–¹æ¡ˆ
                    if not rec_texts:
                        rec_texts = [block.get('text', '') for block in ocr_data.get('text_blocks', [])]
                    
                    # ä¿å­˜OCRç»“æœåˆ°æ•°æ®åº“
                    db_ocr = OCRResult(
                        frame_id=frame.id,
                        text_content=json.dumps(rec_texts, ensure_ascii=False),  # å­˜å‚¨rec_textsæ•°ç»„
                        confidence=ocr_data["total_confidence"],
                        bbox=json.dumps(ocr_data["text_blocks"], ensure_ascii=False)
                    )
                    
                    db.add(db_ocr)
                    processed_frames += 1
                    
                    # æ³¨é‡Šæ‰æ™®é€šæ ¼å¼JSONçš„ä¿å­˜ï¼Œåªä¿ç•™rawæ ¼å¼
                    # self.save_ocr_result_to_file(video_id, frame.frame_number, ocr_data)
                    
                    ocr_results.append({
                        "frame_id": frame.id,
                        "frame_number": frame.frame_number,
                        "timestamp_ms": frame.timestamp_ms,
                        "text_content": ocr_data["full_text"],
                        "confidence": ocr_data["total_confidence"],
                        "text_blocks_count": len(ocr_data["text_blocks"])
                    })
                    
                except Exception as e:
                    failed_frames += 1
                    print(f"å¤„ç†å¸§ {frame.id} OCRå¤±è´¥: {e}")
            
            # æ‰¹é‡æäº¤æ•°æ®åº“æ›´æ”¹
            db.commit()
            
            # æ›´æ–°è§†é¢‘çŠ¶æ€ä¸ºå®Œæˆ
            video.process_status = ProcessStatus.completed
            db.commit()
            
            return {
                "message": "OCRå¤„ç†å®Œæˆ",
                "video_id": video_id,
                "total_frames": len(frames),
                "processed_frames": processed_frames,
                "failed_frames": failed_frames,
                "ocr_results": ocr_results[:10]  # åªè¿”å›å‰10ä¸ªç»“æœä½œä¸ºç¤ºä¾‹
            }
            
        except Exception as e:
            # æ›´æ–°è§†é¢‘çŠ¶æ€ä¸ºå¤±è´¥
            video.process_status = ProcessStatus.failed
            db.commit()
            raise HTTPException(status_code=500, detail=f"OCRå¤„ç†å¤±è´¥: {str(e)}")
    
    def get_video_ocr_results(self, video_id: int, db: Session) -> List[OCRResult]:
        """è·å–è§†é¢‘çš„æ‰€æœ‰OCRç»“æœ"""
        # æ£€æŸ¥è§†é¢‘æ˜¯å¦å­˜åœ¨
        video = db.query(Video).filter(Video.id == video_id).first()
        if not video:
            raise HTTPException(status_code=404, detail="è§†é¢‘ä¸å­˜åœ¨")
        
        # è·å–OCRç»“æœ
        ocr_results = db.query(OCRResult).join(
            VideoFrame, OCRResult.frame_id == VideoFrame.id
        ).filter(
            VideoFrame.video_id == video_id
        ).order_by(VideoFrame.timestamp_ms).all()
        
        return ocr_results
    
    def get_enhanced_ocr_results(self, video_id: int) -> List[EnhancedOCRResultResponse]:
        """è·å–å¢å¼ºçš„OCRç»“æœï¼ˆä»JSONæ–‡ä»¶è¯»å–ï¼‰"""
        try:
            enhanced_results = []
            video_ocr_dir = os.path.join("data", "ocr_results", f"video_{video_id}")
            
            # æ£€æŸ¥ç›®å½•æ˜¯å¦å­˜åœ¨
            if not os.path.exists(video_ocr_dir):
                print(f"OCRç»“æœç›®å½•ä¸å­˜åœ¨: {video_ocr_dir}")
                return []
            
            # æŸ¥æ‰¾è¯¥è§†é¢‘çš„æ‰€æœ‰OCRç»“æœæ–‡ä»¶
            for filename in os.listdir(video_ocr_dir):
                if filename.endswith("_ocr_res.json"):
                    file_path = os.path.join(video_ocr_dir, filename)
                    try:
                        with open(file_path, 'r', encoding='utf-8') as f:
                            ocr_data = json.load(f)
                            
                            # æ‰‹åŠ¨æ„å»ºEnhancedOCRResultResponseå¯¹è±¡
                            enhanced_result = EnhancedOCRResultResponse(
                                frame_id=ocr_data.get('frame_id', 0),
                                frame_path=ocr_data.get('frame_path', ''),
                                ocr_version=ocr_data.get('ocr_version', 'PP-OCRv5'),
                                processing_time=ocr_data.get('processing_time', 0.0),
                                text_blocks=[],  # ç®€åŒ–å¤„ç†
                                full_text='',  # ä»raw_resultä¸­æå–
                                total_confidence=0.0,  # ä»raw_resultä¸­è®¡ç®—
                                text_count=0,  # ä»raw_resultä¸­è®¡ç®—
                                language='zh',  # é»˜è®¤ä¸­æ–‡
                                image_info={},  # ç®€åŒ–å¤„ç†
                                detection_results=[],  # ç®€åŒ–å¤„ç†
                                recognition_results=[],  # ç®€åŒ–å¤„ç†
                                raw_result=ocr_data.get('raw_result', [])
                            )
                            
                            # ä»raw_resultä¸­æå–rec_texts
                            raw_result = ocr_data.get('raw_result', [])
                            all_texts = []
                            for result in raw_result:
                                if isinstance(result, dict) and 'json' in result:
                                    json_data = result['json']
                                    if isinstance(json_data, dict) and 'res' in json_data:
                                        res_data = json_data['res']
                                        if isinstance(res_data, dict) and 'rec_texts' in res_data:
                                            all_texts.extend(res_data['rec_texts'])
                            
                            enhanced_result.full_text = ' '.join(all_texts)
                            enhanced_result.text_count = len(all_texts)
                            
                            enhanced_results.append(enhanced_result)
                            
                    except Exception as e:
                        print(f"è¯»å–OCRç»“æœæ–‡ä»¶å¤±è´¥ {filename}: {e}")
                        continue
            
            # æŒ‰frame_idæ’åº
            enhanced_results.sort(key=lambda x: x.frame_id)
            return enhanced_results
            
        except Exception as e:
            print(f"è·å–å¢å¼ºOCRç»“æœå¤±è´¥: {e}")
            raise HTTPException(status_code=500, detail="è·å–å¢å¼ºOCRç»“æœå¤±è´¥")
    
    def get_frame_ocr_result(self, frame_id: int, db: Session) -> OCRResult:
        """è·å–æŒ‡å®šå¸§çš„OCRç»“æœ"""
        ocr_result = db.query(OCRResult).filter(OCRResult.frame_id == frame_id).first()
        if not ocr_result:
            raise HTTPException(status_code=404, detail="å¸§OCRç»“æœä¸å­˜åœ¨")
        return ocr_result
    
    def analyze_keywords_in_ocr_results(self, video_id: int, keywords: List[str], db: Session) -> List[dict]:
        """åˆ†æOCRç»“æœä¸­çš„å…³é”®è¯å‡ºç°å’Œæ¶ˆå¤±æ¨¡å¼"""
        # è·å–è§†é¢‘çš„æ‰€æœ‰å¸§å’ŒOCRç»“æœ
        frames_with_ocr = db.query(VideoFrame, OCRResult).join(
            OCRResult, VideoFrame.id == OCRResult.frame_id
        ).filter(
            VideoFrame.video_id == video_id
        ).order_by(VideoFrame.timestamp_ms).all()
        
        if not frames_with_ocr:
            return []
        
        # åˆ†ææ¯ä¸ªå…³é”®è¯
        analysis_results = []
        
        for keyword in keywords:
            keyword_analysis = {
                "keyword": keyword,
                "first_appearance_timestamp": None,
                "first_disappearance_timestamp": None,
                "total_occurrences": 0,
                "frame_occurrences": [],
                "pattern_analysis": {
                    "continuous_periods": [],
                    "gap_periods": []
                }
            }
            
            previous_found = False
            current_period_start = None
            
            for frame, ocr_result in frames_with_ocr:
                # æ£€æŸ¥å…³é”®è¯æ˜¯å¦åœ¨OCRæ–‡æœ¬ä¸­
                text_content = ocr_result.text_content or ""
                found_in_frame = keyword.lower() in text_content.lower()
                
                if found_in_frame:
                    keyword_analysis["total_occurrences"] += 1
                    keyword_analysis["frame_occurrences"].append({
                        "frame_id": frame.id,
                        "timestamp_ms": frame.timestamp_ms,
                        "confidence": float(ocr_result.confidence) if ocr_result.confidence else 0.0
                    })
                    
                    # è®°å½•ç¬¬ä¸€æ¬¡å‡ºç°
                    if keyword_analysis["first_appearance_timestamp"] is None:
                        keyword_analysis["first_appearance_timestamp"] = frame.timestamp_ms
                    
                    # å¼€å§‹è¿ç»­æœŸé—´
                    if not previous_found:
                        current_period_start = frame.timestamp_ms
                
                else:
                    # å…³é”®è¯æ¶ˆå¤±
                    if previous_found:
                        # è®°å½•ç¬¬ä¸€æ¬¡æ¶ˆå¤±
                        if keyword_analysis["first_disappearance_timestamp"] is None:
                            keyword_analysis["first_disappearance_timestamp"] = frame.timestamp_ms
                        
                        # ç»“æŸè¿ç»­æœŸé—´
                        if current_period_start is not None:
                            keyword_analysis["pattern_analysis"]["continuous_periods"].append({
                                "start_timestamp": current_period_start,
                                "end_timestamp": frame.timestamp_ms,
                                "duration_ms": frame.timestamp_ms - current_period_start
                            })
                            current_period_start = None
                
                previous_found = found_in_frame
            
            # å¤„ç†æœ€åä¸€ä¸ªè¿ç»­æœŸé—´
            if current_period_start is not None and frames_with_ocr:
                last_frame = frames_with_ocr[-1][0]
                keyword_analysis["pattern_analysis"]["continuous_periods"].append({
                    "start_timestamp": current_period_start,
                    "end_timestamp": last_frame.timestamp_ms,
                    "duration_ms": last_frame.timestamp_ms - current_period_start
                })
            
            analysis_results.append(keyword_analysis)
        
        return analysis_results
    
    async def analyze_video_keywords(self, video_id: int, request: KeywordAnalysisRequest, db: Session) -> dict:
        """åˆ†æè§†é¢‘ä¸­å…³é”®è¯çš„å‡ºç°å’Œæ¶ˆå¤±æ¨¡å¼"""
        # æ£€æŸ¥è§†é¢‘æ˜¯å¦å­˜åœ¨
        video = db.query(Video).filter(Video.id == video_id).first()
        if not video:
            raise HTTPException(status_code=404, detail="è§†é¢‘ä¸å­˜åœ¨")
        
        # æ£€æŸ¥æ˜¯å¦æœ‰OCRç»“æœ
        ocr_count = db.query(OCRResult).join(
            VideoFrame, OCRResult.frame_id == VideoFrame.id
        ).filter(
            VideoFrame.video_id == video_id
        ).count()
        
        if ocr_count == 0:
            raise HTTPException(status_code=404, detail="è§†é¢‘OCRç»“æœä¸å­˜åœ¨ï¼Œè¯·å…ˆè¿›è¡ŒOCRå¤„ç†")
        
        try:
            # æ‰§è¡Œå…³é”®è¯åˆ†æ
            analysis_results = self.analyze_keywords_in_ocr_results(video_id, request.keywords, db)
            
            return {
                "message": "å…³é”®è¯åˆ†æå®Œæˆ",
                "video_id": video_id,
                "analyzed_keywords": len(request.keywords),
                "analysis_results": analysis_results
            }
            
        except Exception as e:
            raise HTTPException(status_code=500, detail=f"å…³é”®è¯åˆ†æå¤±è´¥: {str(e)}")
    
    async def analyze_stage_keywords(self, video_id: int, db: Session) -> dict:
        """åŸºäºstage_configsåˆ†æå…³é”®è¯æ¨¡å¼"""
        # æ£€æŸ¥è§†é¢‘æ˜¯å¦å­˜åœ¨
        video = db.query(Video).filter(Video.id == video_id).first()
        if not video:
            raise HTTPException(status_code=404, detail="è§†é¢‘ä¸å­˜åœ¨")
        
        # è·å–è§†é¢‘çš„é˜¶æ®µé…ç½®
        stage_configs = db.query(StageConfig).filter(
            StageConfig.video_id == video_id
        ).order_by(StageConfig.stage_order).all()
        
        if not stage_configs:
            raise HTTPException(status_code=404, detail="è§†é¢‘é˜¶æ®µé…ç½®ä¸å­˜åœ¨")
        
        # æ£€æŸ¥æ˜¯å¦æœ‰OCRç»“æœ
        ocr_count = db.query(OCRResult).join(
            VideoFrame, OCRResult.frame_id == VideoFrame.id
        ).filter(
            VideoFrame.video_id == video_id
        ).count()
        
        if ocr_count == 0:
            raise HTTPException(status_code=404, detail="è§†é¢‘OCRç»“æœä¸å­˜åœ¨ï¼Œè¯·å…ˆè¿›è¡ŒOCRå¤„ç†")
        
        try:
            stage_analysis_results = []
            
            for config in stage_configs:
                # è§£æå…³é”®è¯
                keywords = json.loads(config.keywords) if isinstance(config.keywords, str) else config.keywords
                
                # åˆ†æå…³é”®è¯
                analysis_results = self.analyze_keywords_in_ocr_results(video_id, keywords, db)
                
                stage_analysis_results.append({
                    "stage_id": config.id,
                    "stage_name": config.stage_name,
                    "stage_order": config.stage_order,
                    "keywords": keywords,
                    "keyword_analysis": analysis_results
                })
            
            return {
                "message": "é˜¶æ®µå…³é”®è¯åˆ†æå®Œæˆ",
                "video_id": video_id,
                "total_stages": len(stage_configs),
                "stage_analysis_results": stage_analysis_results
            }
            
        except Exception as e:
            raise HTTPException(status_code=500, detail=f"é˜¶æ®µå…³é”®è¯åˆ†æå¤±è´¥: {str(e)}")
    
    async def analyze_keywords_by_stage_config(self, config_id: int, db: Session) -> dict:
        """åŸºäºé˜¶æ®µé…ç½®è¿›è¡Œå…³é”®è¯åˆ†æ"""
        try:
            # è·å–é˜¶æ®µé…ç½®
            stage_config = db.query(StageConfig).filter(StageConfig.id == config_id).first()
            if not stage_config:
                raise HTTPException(status_code=404, detail="é˜¶æ®µé…ç½®ä¸å­˜åœ¨")
            
            # è§£æå…³é”®è¯
            keywords = json.loads(stage_config.keywords) if isinstance(stage_config.keywords, str) else stage_config.keywords
            if not keywords:
                raise HTTPException(status_code=400, detail="é˜¶æ®µé…ç½®ä¸­æ²¡æœ‰å…³é”®è¯")
            
            # æ‰§è¡Œå…³é”®è¯åˆ†æ
            analysis_results = self.analyze_keywords_in_ocr_results(stage_config.video_id, keywords, db)
            
            return {
                "message": "åŸºäºé˜¶æ®µé…ç½®çš„å…³é”®è¯åˆ†æå®Œæˆ",
                "stage_config_id": config_id,
                "video_id": stage_config.video_id,
                "stage_name": stage_config.stage_name,
                "keywords_count": len(keywords),
                "analysis_results": analysis_results
            }
            
        except Exception as e:
            raise HTTPException(status_code=500, detail=f"å…³é”®è¯åˆ†æå¤±è´¥: {str(e)}")
    
    def delete_video_ocr_results(self, video_id: int, db: Session) -> dict:
        """åˆ é™¤è§†é¢‘çš„æ‰€æœ‰OCRç»“æœï¼ˆæ•°æ®åº“è®°å½•å’ŒJSONæ–‡ä»¶ï¼‰"""
        try:
            # æ£€æŸ¥è§†é¢‘æ˜¯å¦å­˜åœ¨
            video = db.query(Video).filter(Video.id == video_id).first()
            if not video:
                raise HTTPException(status_code=404, detail="è§†é¢‘ä¸å­˜åœ¨")
            
            # è·å–è§†é¢‘çš„æ‰€æœ‰å¸§
            frames = db.query(VideoFrame).filter(VideoFrame.video_id == video_id).all()
            
            deleted_db_records = 0
            deleted_json_files = 0
            
            # åˆ é™¤æ•°æ®åº“ä¸­çš„OCRè®°å½•
            for frame in frames:
                ocr_results = db.query(OCRResult).filter(OCRResult.frame_id == frame.id).all()
                for ocr_result in ocr_results:
                    db.delete(ocr_result)
                    deleted_db_records += 1
            
            # æäº¤æ•°æ®åº“æ›´æ”¹
            db.commit()
            
            # åˆ é™¤JSONæ–‡ä»¶
            ocr_output_dir = Path(f"{self.ocr_results_path}/video_{video_id}")
            if ocr_output_dir.exists():
                import shutil
                for json_file in ocr_output_dir.glob("*.json"):
                    try:
                        json_file.unlink()
                        deleted_json_files += 1
                    except Exception as e:
                        print(f"åˆ é™¤JSONæ–‡ä»¶å¤±è´¥: {json_file}, é”™è¯¯: {e}")
                
                # å¦‚æœç›®å½•ä¸ºç©ºï¼Œåˆ é™¤ç›®å½•
                try:
                    if not any(ocr_output_dir.iterdir()):
                        ocr_output_dir.rmdir()
                except Exception as e:
                    print(f"åˆ é™¤ç›®å½•å¤±è´¥: {ocr_output_dir}, é”™è¯¯: {e}")
            
            return {
                "message": "OCRç»“æœåˆ é™¤æˆåŠŸ",
                "video_id": video_id,
                "deleted_db_records": deleted_db_records,
                "deleted_json_files": deleted_json_files
            }
            
        except Exception as e:
            db.rollback()
            raise HTTPException(status_code=500, detail=f"åˆ é™¤OCRç»“æœå¤±è´¥: {str(e)}")
    
    def get_ocr_storage_info(self, video_id: int, db: Session) -> dict:
        """è·å–OCRç»“æœçš„å­˜å‚¨ä¿¡æ¯"""
        try:
            # æ£€æŸ¥è§†é¢‘æ˜¯å¦å­˜åœ¨
            video = db.query(Video).filter(Video.id == video_id).first()
            if not video:
                raise HTTPException(status_code=404, detail="è§†é¢‘ä¸å­˜åœ¨")
            
            # ç»Ÿè®¡æ•°æ®åº“ä¸­çš„OCRè®°å½•
            frames = db.query(VideoFrame).filter(VideoFrame.video_id == video_id).all()
            total_frames = len(frames)
            
            db_ocr_count = 0
            for frame in frames:
                ocr_count = db.query(OCRResult).filter(OCRResult.frame_id == frame.id).count()
                db_ocr_count += ocr_count
            
            # æ£€æŸ¥JSONæ–‡ä»¶å­˜å‚¨
            ocr_output_dir = Path(f"{self.ocr_results_path}/video_{video_id}")
            json_files_count = 0
            if ocr_output_dir.exists():
                json_files_count = len(list(ocr_output_dir.glob("*.json")))
            
            # æ£€æŸ¥OCRå›¾ç‰‡å­˜å‚¨
            ocr_image_dir = Path(f"{self.ocr_images_path}/video_{video_id}")
            image_files_count = 0
            if ocr_image_dir.exists():
                image_files_count = len(list(ocr_image_dir.glob("*.jpg")))
            
            return {
                "video_id": video_id,
                "total_frames": total_frames,
                "database_ocr_records": db_ocr_count,
                "json_files_count": json_files_count,
                "ocr_images_count": image_files_count,
                "storage_paths": {
                    "ocr_results": str(ocr_output_dir),
                    "ocr_images": str(ocr_image_dir)
                }
            }
            
        except Exception as e:
            raise HTTPException(status_code=500, detail=f"è·å–OCRå­˜å‚¨ä¿¡æ¯å¤±è´¥: {str(e)}")
    
    def get_video_ocr_images(self, video_id: int) -> List[dict]:
        """è·å–è§†é¢‘çš„æ‰€æœ‰OCRå¤„ç†åå›¾ç‰‡åˆ—è¡¨"""
        try:
            ocr_image_dir = Path(f"{self.ocr_images_path}/video_{video_id}")
            if not ocr_image_dir.exists():
                return []
            
            ocr_images = []
            for image_file in ocr_image_dir.glob("*.jpg"):
                # ä»æ–‡ä»¶åæå–frame_id
                filename = image_file.stem  # å»æ‰æ‰©å±•å
                if filename.startswith("frame_") and filename.endswith("_ocr"):
                    try:
                        frame_id = int(filename.split("_")[1])
                        file_stat = image_file.stat()
                        
                        ocr_images.append({
                            "frame_id": frame_id,
                            "filename": image_file.name,
                            "file_path": str(image_file),
                            "file_size": file_stat.st_size,
                            "created_at": datetime.fromtimestamp(file_stat.st_ctime).isoformat(),
                            "modified_at": datetime.fromtimestamp(file_stat.st_mtime).isoformat()
                        })
                    except (ValueError, IndexError) as e:
                        print(f"è§£æOCRå›¾ç‰‡æ–‡ä»¶åå¤±è´¥: {filename}, é”™è¯¯: {e}")
                        continue
            
            # æŒ‰frame_idæ’åº
            ocr_images.sort(key=lambda x: x["frame_id"])
            return ocr_images
            
        except Exception as e:
            raise HTTPException(status_code=500, detail=f"è·å–OCRå›¾ç‰‡åˆ—è¡¨å¤±è´¥: {str(e)}")
    
    def get_frame_ocr_image_path(self, video_id: int, frame_id: int) -> str:
        """è·å–æŒ‡å®šå¸§çš„OCRå›¾ç‰‡è·¯å¾„"""
        ocr_image_path = Path(f"{self.ocr_images_path}/video_{video_id}/frame_{frame_id}_ocr.jpg")
        if not ocr_image_path.exists():
            raise HTTPException(status_code=404, detail="OCRå›¾ç‰‡ä¸å­˜åœ¨")
        return str(ocr_image_path)
    
    def delete_video_ocr_images(self, video_id: int) -> dict:
        """åˆ é™¤è§†é¢‘çš„æ‰€æœ‰OCRå›¾ç‰‡"""
        try:
            ocr_image_dir = Path(f"{self.ocr_images_path}/video_{video_id}")
            deleted_files = 0
            
            if ocr_image_dir.exists():
                for image_file in ocr_image_dir.glob("*.jpg"):
                    try:
                        image_file.unlink()
                        deleted_files += 1
                    except Exception as e:
                        print(f"åˆ é™¤OCRå›¾ç‰‡å¤±è´¥: {image_file}, é”™è¯¯: {e}")
                
                # å¦‚æœç›®å½•ä¸ºç©ºï¼Œåˆ é™¤ç›®å½•
                try:
                    if not any(ocr_image_dir.iterdir()):
                        ocr_image_dir.rmdir()
                except Exception as e:
                    print(f"åˆ é™¤OCRå›¾ç‰‡ç›®å½•å¤±è´¥: {ocr_image_dir}, é”™è¯¯: {e}")
            
            return {
                "message": "OCRå›¾ç‰‡åˆ é™¤æˆåŠŸ",
                "video_id": video_id,
                "deleted_files": deleted_files
            }
            
        except Exception as e:
            raise HTTPException(status_code=500, detail=f"åˆ é™¤OCRå›¾ç‰‡å¤±è´¥: {str(e)}")
    
    def view_video_ocr_results(self, video_id: int, db: Session) -> dict:
        """æŸ¥çœ‹è§†é¢‘çš„OCRç»“æœï¼ˆåŒ…å«æ•°æ®åº“å’ŒJSONæ–‡ä»¶ä¿¡æ¯ï¼‰"""
        try:
            # è·å–æ•°æ®åº“ä¸­çš„OCRç»“æœ
            db_results = self.get_video_ocr_results(video_id, db)
            
            # è·å–JSONæ–‡ä»¶ä¸­çš„å¢å¼ºOCRç»“æœ
            json_results = self.get_enhanced_ocr_results(video_id)
            
            # ç»Ÿè®¡ä¿¡æ¯
            stats = {
                "video_id": video_id,
                "database_records_count": len(db_results),
                "json_files_count": len(json_results),
                "data_consistency": len(db_results) == len(json_results)
            }
            
            # è¿”å›å®Œæ•´ä¿¡æ¯
            return {
                "stats": stats,
                "database_results": [{
                    "id": result.id,
                    "frame_id": result.frame_id,
                    "text_content": self._parse_text_content(result.text_content),
                    "confidence": float(result.confidence) if result.confidence else None,
                    "bbox": result.bbox,
                    "processed_at": result.processed_at.isoformat() if result.processed_at else None
                } for result in db_results],
                "json_results": [{
                    "frame_id": result.frame_id,
                    "frame_path": result.frame_path,
                    "ocr_version": result.ocr_version,
                    "processing_time": result.processing_time,
                    "text_blocks_count": len(result.text_blocks) if result.text_blocks else 0,
                    "has_raw_result": result.raw_result is not None
                } for result in json_results]
            }
            
        except Exception as e:
            print(f"æŸ¥çœ‹OCRç»“æœå¤±è´¥: {e}")
            raise HTTPException(status_code=500, detail=f"æŸ¥çœ‹OCRç»“æœå¤±è´¥: {str(e)}")
    
    def _parse_text_content(self, text_content: str):
        """è§£ææ•°æ®åº“ä¸­å­˜å‚¨çš„text_contentå­—æ®µ"""
        try:
            # å°è¯•è§£æä¸ºJSONæ•°ç»„ï¼ˆæ–°æ ¼å¼ï¼‰
            parsed = json.loads(text_content)
            if isinstance(parsed, list):
                return parsed  # è¿”å›rec_textsæ•°ç»„
            else:
                return text_content  # è¿”å›åŸå§‹å­—ç¬¦ä¸²
        except (json.JSONDecodeError, TypeError):
            # å¦‚æœè§£æå¤±è´¥ï¼Œè¿”å›åŸå§‹å­—ç¬¦ä¸²
            return text_content
    
    def delete_frame_ocr_image(self, video_id: int, frame_id: int) -> dict:
        """åˆ é™¤æŒ‡å®šå¸§çš„OCRå›¾ç‰‡"""
        try:
            ocr_image_path = Path(f"{self.ocr_images_path}/video_{video_id}/frame_{frame_id}_ocr.jpg")
            
            if not ocr_image_path.exists():
                raise HTTPException(status_code=404, detail="OCRå›¾ç‰‡ä¸å­˜åœ¨")
            
            ocr_image_path.unlink()
            
            return {
                "message": "OCRå›¾ç‰‡åˆ é™¤æˆåŠŸ",
                "video_id": video_id,
                "frame_id": frame_id,
                "deleted_file": str(ocr_image_path)
            }
            
        except Exception as e:
            raise HTTPException(status_code=500, detail=f"åˆ é™¤OCRå›¾ç‰‡å¤±è´¥: {str(e)}")


# åˆ›å»ºå…¨å±€OCRå¤„ç†å™¨å®ä¾‹
ocr_processor = OCRProcessor()