# -*- coding: utf-8 -*-
"""
OCRè¯†åˆ«æ¨¡å—
è´Ÿè´£è§†é¢‘å¸§çš„OCRè¯†åˆ«ã€å…³é”®è¯åˆ†æç­‰åŠŸèƒ½
"""

from fastapi import HTTPException, Depends
from sqlalchemy.orm import Session
from models_simple import Video, VideoFrame, OCRResult, StageConfig, ProcessStatus
from pathlib import Path
from typing import List, Optional, Dict, Any
from pydantic import BaseModel
from datetime import datetime
from paddleocr import PaddleOCR, TextRecognition
from config import OCRConfig
import json
import os
import time
import cv2


class OCRProcessRequest(BaseModel):
    use_gpu: Optional[bool] = False
    lang: Optional[str] = "ch"  # è¯­è¨€ï¼šch, enç­‰


class OCRResultResponse(BaseModel):
    id: int
    frame_id: int
    text_content: Optional[str]
    confidence: Optional[float]
    bbox: Optional[str]  # Store as JSON string to avoid serialization issues
    processed_at: datetime
    
    class Config:
        from_attributes = True


class EnhancedOCRResultResponse(BaseModel):
    """å¢å¼ºçš„OCRç»“æœå“åº”æ¨¡å‹ - æ”¯æŒPP-OCRv5"""
    frame_id: int
    frame_path: str
    ocr_version: str
    processing_time: float
    text_blocks: List[Dict[str, Any]]
    full_text: str
    total_confidence: float
    text_count: int
    language: str
    image_info: Dict[str, Any]
    detection_results: List[Dict[str, Any]]
    recognition_results: List[Dict[str, Any]]
    
    class Config:
        from_attributes = True


class KeywordAnalysisRequest(BaseModel):
    keywords: List[str]
    analysis_type: Optional[str] = "appearance"  # appearance, disappearance, both


class KeywordAnalysisResponse(BaseModel):
    keyword: str
    first_appearance_timestamp: Optional[int]
    first_disappearance_timestamp: Optional[int]
    total_occurrences: int
    frame_occurrences: List[dict]


class OCRProcessor:
    """OCRå¤„ç†å™¨"""
    
    def __init__(self):
        self.ocr_instance = None
        self.ocr_results_path = "./data/ocr_results"
        
        # ç¡®ä¿OCRç»“æœå­˜å‚¨ç›®å½•å­˜åœ¨
        Path(self.ocr_results_path).mkdir(parents=True, exist_ok=True)
        
        # åˆå§‹åŒ–OCRå®ä¾‹
        self.initialize_ocr()
    
    def initialize_ocr(self, use_gpu: bool = False, lang: str = "ch") -> None:
        """åˆå§‹åŒ–OCRå®ä¾‹ - ä¼˜åŒ–çš„PaddleOCRé…ç½®"""
        try:
            # å…ˆå°è¯•ä½¿ç”¨æ–°ç‰ˆTextRecognition API
            try:
                self.text_recognition = TextRecognition()
                print("âœ“ TextRecognitionæ¨¡å‹åˆå§‹åŒ–æˆåŠŸ")
            except Exception as te:
                print(f"âš  TextRecognitionåˆå§‹åŒ–å¤±è´¥: {te}")
                self.text_recognition = None
            
            # ä½¿ç”¨ä¼˜åŒ–çš„PaddleOCRé…ç½®
            self.ocr_instance = PaddleOCR(
                use_angle_cls=True, 
                lang='ch',
                show_log=False,  # å‡å°‘æ—¥å¿—è¾“å‡º
                use_gpu=use_gpu
            )
            print("âœ“ PaddleOCRé…ç½®åˆå§‹åŒ–æˆåŠŸ")
            
        except Exception as e:
            print(f"âš  OCRåˆå§‹åŒ–å¤±è´¥: {e}")
            # æœ€åŸºæœ¬çš„é…ç½®
            self.text_recognition = None
            self.ocr_instance = PaddleOCR(use_angle_cls=True, lang='ch')
            print("âœ“ ä½¿ç”¨åŸºç¡€PaddleOCRé…ç½®")
    
    def process_frame_ocr(self, frame_path: str, frame_id: int, use_gpu: bool = False, lang: str = "ch") -> dict:
        """å¯¹å•ä¸ªå¸§è¿›è¡ŒOCRè¯†åˆ«"""
        if not self.ocr_instance:
            raise ValueError("OCRå®ä¾‹æœªåˆå§‹åŒ–")
        
        if not os.path.exists(frame_path):
            raise ValueError(f"å¸§å›¾ç‰‡æ–‡ä»¶ä¸å­˜åœ¨: {frame_path}")
        
        try:
            # è·å–å›¾åƒä¿¡æ¯
            image = cv2.imread(frame_path)
            if image is None:
                print(f"âš  æ— æ³•è¯»å–å›¾åƒæ–‡ä»¶: {frame_path}")
                raise ValueError(f"æ— æ³•è¯»å–å›¾åƒæ–‡ä»¶: {frame_path}")
            
            image_height, image_width = image.shape[:2]
            image_channels = image.shape[2] if len(image.shape) > 2 else None
            print(f"ğŸ“· å›¾åƒä¿¡æ¯: {image_width}x{image_height}, é€šé“æ•°: {image_channels}")
            
            # è®°å½•å¤„ç†å¼€å§‹æ—¶é—´
            start_time = time.time()
            
            # æ‰§è¡ŒOCRè¯†åˆ« - ä½¿ç”¨æ—§ç‰ˆAPIï¼ˆæ›´ç¨³å®šï¼‰
            print(f"ğŸ” å¼€å§‹OCRè¯†åˆ«: {frame_path}")
            result = self.ocr_instance.ocr(frame_path)
            print(f"ğŸ“ OCRåŸå§‹ç»“æœ: {result}")
            
            # è®¡ç®—å¤„ç†æ—¶é—´
            processing_time = time.time() - start_time
            
            # å¤„ç†OCRç»“æœ - å¢å¼ºçš„JSONç»“æ„
            ocr_data = {
                "frame_id": frame_id,
                "frame_path": frame_path,
                "ocr_version": "PP-OCRv5",
                "processing_time": round(processing_time, 3),
                "text_blocks": [],
                "full_text": "",
                "total_confidence": 0.0,
                "text_count": 0,
                "language": lang,
                "image_info": {
                    "width": image_width,
                    "height": image_height,
                    "channels": image_channels
                },
                "detection_results": [],
                "recognition_results": []
            }
            
            # å¤„ç†ä¸åŒæ ¼å¼çš„OCRç»“æœ
            if result:
                text_blocks = []
                confidences = []
                full_text_parts = []
                detection_results = []
                recognition_results = []
                
                # æ£€æŸ¥æ˜¯å¦æ˜¯æ–°ç‰ˆTextRecognition APIçš„ç»“æœæ ¼å¼
                if isinstance(result, list) and len(result) > 0 and isinstance(result[0], dict):
                    # æ–°ç‰ˆAPIæ ¼å¼å¤„ç†
                    result_dict = result[0]
                    if 'rec_texts' in result_dict and 'rec_scores' in result_dict:
                        rec_texts = result_dict['rec_texts']
                        rec_scores = result_dict['rec_scores']
                        
                        for idx, (text, score) in enumerate(zip(rec_texts, rec_scores)):
                            if text.strip():  # åªå¤„ç†éç©ºæ–‡æœ¬
                                # æ¨¡æ‹Ÿè¾¹ç•Œæ¡†ï¼ˆæ–°ç‰ˆAPIå¯èƒ½ä¸æä¾›è¯¦ç»†åæ ‡ï¼‰
                                bbox = [[0, idx*20], [100, idx*20], [100, (idx+1)*20], [0, (idx+1)*20]]
                                
                                text_block = {
                                    "id": idx,
                                    "text": text,
                                    "confidence": float(score),
                                    "bbox": bbox,
                                    "bbox_normalized": {
                                        "x1": 0,
                                        "y1": idx*20,
                                        "x2": 100,
                                        "y2": (idx+1)*20
                                    },
                                    "text_length": len(text),
                                    "word_count": len(text.split()) if text.strip() else 0
                                }
                                
                                detection_result = {
                                    "id": idx,
                                    "bbox": bbox,
                                    "confidence": float(score)
                                }
                                
                                recognition_result = {
                                    "id": idx,
                                    "text": text,
                                    "confidence": float(score)
                                }
                                
                                text_blocks.append(text_block)
                                detection_results.append(detection_result)
                                recognition_results.append(recognition_result)
                                confidences.append(float(score))
                                full_text_parts.append(text)
                elif isinstance(result, list) and len(result) > 0 and isinstance(result[0], list):
                     # æ—§ç‰ˆAPIæ ¼å¼å¤„ç†
                     for idx, line in enumerate(result[0]):
                         if len(line) >= 2:
                             bbox = line[0]  # è¾¹ç•Œæ¡†åæ ‡
                             text_info = line[1]  # æ–‡æœ¬å’Œç½®ä¿¡åº¦
                             
                             if isinstance(text_info, (list, tuple)) and len(text_info) >= 2:
                                 text = text_info[0]
                                 confidence = float(text_info[1])
                                 
                                 # è¯¦ç»†çš„æ–‡æœ¬å—ä¿¡æ¯
                                 text_block = {
                                     "id": idx,
                                     "text": text,
                                     "confidence": confidence,
                                     "bbox": bbox,
                                     "bbox_normalized": {
                                         "x1": min([point[0] for point in bbox]),
                                         "y1": min([point[1] for point in bbox]),
                                         "x2": max([point[0] for point in bbox]),
                                         "y2": max([point[1] for point in bbox])
                                     },
                                     "text_length": len(text),
                                     "word_count": len(text.split()) if text.strip() else 0
                                 }
                                 
                                 # æ£€æµ‹ç»“æœ
                                 detection_result = {
                                     "id": idx,
                                     "bbox": bbox,
                                     "confidence": confidence
                                 }
                                 
                                 # è¯†åˆ«ç»“æœ
                                 recognition_result = {
                                     "id": idx,
                                     "text": text,
                                     "confidence": confidence,
                                     "char_confidences": []  # å¯ä»¥æ‰©å±•ä¸ºå­—ç¬¦çº§ç½®ä¿¡åº¦
                                 }
                                 
                                 text_blocks.append(text_block)
                                 detection_results.append(detection_result)
                                 recognition_results.append(recognition_result)
                                 confidences.append(confidence)
                                 full_text_parts.append(text)
                
                ocr_data["text_blocks"] = text_blocks
                ocr_data["detection_results"] = detection_results
                ocr_data["recognition_results"] = recognition_results
                ocr_data["full_text"] = " ".join(full_text_parts)
                ocr_data["total_confidence"] = sum(confidences) / len(confidences) if confidences else 0.0
                ocr_data["text_count"] = len(text_blocks)
            
            return ocr_data
            
        except Exception as e:
            raise ValueError(f"OCRå¤„ç†å¤±è´¥: {str(e)}")
    
    def _convert_new_api_result(self, output, frame_path: str):
        """è½¬æ¢æ–°ç‰ˆAPIç»“æœä¸ºæ—§ç‰ˆæ ¼å¼"""
        try:
            # ä¿å­˜OCRå¤„ç†åçš„å›¾ç‰‡å’ŒJSON
            output_dir = Path(f"{self.ocr_results_path}/ocr_output")
            output_dir.mkdir(parents=True, exist_ok=True)
            
            # ä¿å­˜ç»“æœå›¾ç‰‡å’ŒJSON
            for res in output:
                res.save_to_img(save_path=str(output_dir))
                res.save_to_json(save_path=str(output_dir / "result.json"))
            
            # è½¬æ¢ä¸ºæ—§ç‰ˆæ ¼å¼ - è¿™é‡Œéœ€è¦æ ¹æ®æ–°ç‰ˆAPIçš„å®é™…è¾“å‡ºç»“æ„è°ƒæ•´
            converted_result = []
            for res in output:
                # æ–°ç‰ˆAPIçš„ç»“æœç»“æ„å¯èƒ½ä¸åŒï¼Œè¿™é‡ŒåšåŸºæœ¬è½¬æ¢
                # å…·ä½“è½¬æ¢é€»è¾‘éœ€è¦æ ¹æ®å®é™…APIè¾“å‡ºè°ƒæ•´
                if hasattr(res, 'text') and hasattr(res, 'confidence'):
                    converted_result.append([
                        [[0, 0], [100, 0], [100, 30], [0, 30]],  # é»˜è®¤è¾¹ç•Œæ¡†
                        [res.text, res.confidence]
                    ])
            
            return [converted_result] if converted_result else [[]]
            
        except Exception as e:
            print(f"æ–°ç‰ˆAPIç»“æœè½¬æ¢å¤±è´¥: {e}")
            return [[]]
    
    def save_ocr_result_to_file(self, video_id: int, frame_number: int, ocr_data: dict) -> str:
        """ä¿å­˜OCRç»“æœåˆ°JSONæ–‡ä»¶"""
        ocr_output_dir = Path(f"{self.ocr_results_path}/video_{video_id}")
        ocr_output_dir.mkdir(parents=True, exist_ok=True)
        
        ocr_json_path = ocr_output_dir / f"frame_{frame_number}_ocr.json"
        with open(ocr_json_path, 'w', encoding='utf-8') as f:
            json.dump(ocr_data, f, ensure_ascii=False, indent=2)
        
        return str(ocr_json_path)
    
    async def process_video_ocr(self, video_id: int, request: OCRProcessRequest, db: Session) -> dict:
        """å¯¹è§†é¢‘çš„æ‰€æœ‰å¸§è¿›è¡ŒOCRå¤„ç†"""
        # æ£€æŸ¥è§†é¢‘æ˜¯å¦å­˜åœ¨
        video = db.query(Video).filter(Video.id == video_id).first()
        if not video:
            raise HTTPException(status_code=404, detail="è§†é¢‘ä¸å­˜åœ¨")
        
        # è·å–è§†é¢‘çš„æ‰€æœ‰å¸§
        frames = db.query(VideoFrame).filter(VideoFrame.video_id == video_id).order_by(VideoFrame.frame_number).all()
        if not frames:
            raise HTTPException(status_code=404, detail="è§†é¢‘å¸§ä¸å­˜åœ¨ï¼Œè¯·å…ˆè¿›è¡Œåˆ†å¸§å¤„ç†")
        
        try:
            # æ›´æ–°è§†é¢‘çŠ¶æ€ä¸ºå¤„ç†ä¸­
            video.process_status = ProcessStatus.processing
            db.commit()
            
            processed_frames = 0
            failed_frames = 0
            ocr_results = []
            
            for frame in frames:
                try:
                    print(f"ğŸ¬ å¤„ç†å¸§: {frame.id}, è·¯å¾„: {frame.frame_path}")
                    
                    # æ£€æŸ¥æ˜¯å¦å·²ç»å¤„ç†è¿‡OCR
                    existing_ocr = db.query(OCRResult).filter(OCRResult.frame_id == frame.id).first()
                    if existing_ocr:
                        print(f"â­ è·³è¿‡å·²å¤„ç†çš„å¸§: {frame.id}")
                        continue
                    
                    # å¤„ç†OCR
                    print(f"ğŸ” å¼€å§‹å¤„ç†å¸§ {frame.id} çš„OCR")
                    ocr_data = self.process_frame_ocr(frame.frame_path, frame.id, request.use_gpu, request.lang)
                    print(f"âœ… å¸§ {frame.id} OCRå¤„ç†å®Œæˆï¼Œæ–‡æœ¬æ•°é‡: {ocr_data.get('text_count', 0)}")
                    
                    # ä¿å­˜OCRç»“æœåˆ°æ•°æ®åº“
                    db_ocr = OCRResult(
                        frame_id=frame.id,
                        text_content=ocr_data["full_text"],
                        confidence=ocr_data["total_confidence"],
                        bbox=json.dumps(ocr_data["text_blocks"], ensure_ascii=False)
                    )
                    
                    db.add(db_ocr)
                    processed_frames += 1
                    
                    # ä¿å­˜OCRç»“æœåˆ°JSONæ–‡ä»¶
                    self.save_ocr_result_to_file(video_id, frame.frame_number, ocr_data)
                    
                    ocr_results.append({
                        "frame_id": frame.id,
                        "frame_number": frame.frame_number,
                        "timestamp_ms": frame.timestamp_ms,
                        "text_content": ocr_data["full_text"],
                        "confidence": ocr_data["total_confidence"],
                        "text_blocks_count": len(ocr_data["text_blocks"])
                    })
                    
                except Exception as e:
                    failed_frames += 1
                    print(f"å¤„ç†å¸§ {frame.id} OCRå¤±è´¥: {e}")
            
            # æ‰¹é‡æäº¤æ•°æ®åº“æ›´æ”¹
            db.commit()
            
            # æ›´æ–°è§†é¢‘çŠ¶æ€ä¸ºå®Œæˆ
            video.process_status = ProcessStatus.completed
            db.commit()
            
            return {
                "message": "OCRå¤„ç†å®Œæˆ",
                "video_id": video_id,
                "total_frames": len(frames),
                "processed_frames": processed_frames,
                "failed_frames": failed_frames,
                "ocr_results": ocr_results[:10]  # åªè¿”å›å‰10ä¸ªç»“æœä½œä¸ºç¤ºä¾‹
            }
            
        except Exception as e:
            # æ›´æ–°è§†é¢‘çŠ¶æ€ä¸ºå¤±è´¥
            video.process_status = ProcessStatus.failed
            db.commit()
            raise HTTPException(status_code=500, detail=f"OCRå¤„ç†å¤±è´¥: {str(e)}")
    
    def get_video_ocr_results(self, video_id: int, db: Session) -> List[OCRResult]:
        """è·å–è§†é¢‘çš„æ‰€æœ‰OCRç»“æœ"""
        # æ£€æŸ¥è§†é¢‘æ˜¯å¦å­˜åœ¨
        video = db.query(Video).filter(Video.id == video_id).first()
        if not video:
            raise HTTPException(status_code=404, detail="è§†é¢‘ä¸å­˜åœ¨")
        
        # è·å–OCRç»“æœ
        ocr_results = db.query(OCRResult).join(
            VideoFrame, OCRResult.frame_id == VideoFrame.id
        ).filter(
            VideoFrame.video_id == video_id
        ).order_by(VideoFrame.timestamp_ms).all()
        
        return ocr_results
    
    def get_enhanced_ocr_results(self, video_id: int) -> List[EnhancedOCRResultResponse]:
        """è·å–å¢å¼ºçš„OCRç»“æœï¼ˆä»JSONæ–‡ä»¶è¯»å–ï¼‰"""
        try:
            enhanced_results = []
            ocr_results_dir = os.path.join("data", "ocr_results")
            
            # æŸ¥æ‰¾è¯¥è§†é¢‘çš„æ‰€æœ‰OCRç»“æœæ–‡ä»¶
            for filename in os.listdir(ocr_results_dir):
                if filename.startswith(f"video_{video_id}_frame_") and filename.endswith(".json"):
                    file_path = os.path.join(ocr_results_dir, filename)
                    try:
                        with open(file_path, 'r', encoding='utf-8') as f:
                            ocr_data = json.load(f)
                            enhanced_results.append(EnhancedOCRResultResponse(**ocr_data))
                    except Exception as e:
                        print(f"è¯»å–OCRç»“æœæ–‡ä»¶å¤±è´¥ {filename}: {e}")
                        continue
            
            # æŒ‰frame_idæ’åº
            enhanced_results.sort(key=lambda x: x.frame_id)
            return enhanced_results
            
        except Exception as e:
            print(f"è·å–å¢å¼ºOCRç»“æœå¤±è´¥: {e}")
            raise HTTPException(status_code=500, detail="è·å–å¢å¼ºOCRç»“æœå¤±è´¥")
    
    def get_frame_ocr_result(self, frame_id: int, db: Session) -> OCRResult:
        """è·å–æŒ‡å®šå¸§çš„OCRç»“æœ"""
        ocr_result = db.query(OCRResult).filter(OCRResult.frame_id == frame_id).first()
        if not ocr_result:
            raise HTTPException(status_code=404, detail="å¸§OCRç»“æœä¸å­˜åœ¨")
        return ocr_result
    
    def analyze_keywords_in_ocr_results(self, video_id: int, keywords: List[str], db: Session) -> List[dict]:
        """åˆ†æOCRç»“æœä¸­çš„å…³é”®è¯å‡ºç°å’Œæ¶ˆå¤±æ¨¡å¼"""
        # è·å–è§†é¢‘çš„æ‰€æœ‰å¸§å’ŒOCRç»“æœ
        frames_with_ocr = db.query(VideoFrame, OCRResult).join(
            OCRResult, VideoFrame.id == OCRResult.frame_id
        ).filter(
            VideoFrame.video_id == video_id
        ).order_by(VideoFrame.timestamp_ms).all()
        
        if not frames_with_ocr:
            return []
        
        # åˆ†ææ¯ä¸ªå…³é”®è¯
        analysis_results = []
        
        for keyword in keywords:
            keyword_analysis = {
                "keyword": keyword,
                "first_appearance_timestamp": None,
                "first_disappearance_timestamp": None,
                "total_occurrences": 0,
                "frame_occurrences": [],
                "pattern_analysis": {
                    "continuous_periods": [],
                    "gap_periods": []
                }
            }
            
            previous_found = False
            current_period_start = None
            
            for frame, ocr_result in frames_with_ocr:
                # æ£€æŸ¥å…³é”®è¯æ˜¯å¦åœ¨OCRæ–‡æœ¬ä¸­
                text_content = ocr_result.text_content or ""
                found_in_frame = keyword.lower() in text_content.lower()
                
                if found_in_frame:
                    keyword_analysis["total_occurrences"] += 1
                    keyword_analysis["frame_occurrences"].append({
                        "frame_id": frame.id,
                        "timestamp_ms": frame.timestamp_ms,
                        "confidence": float(ocr_result.confidence) if ocr_result.confidence else 0.0
                    })
                    
                    # è®°å½•ç¬¬ä¸€æ¬¡å‡ºç°
                    if keyword_analysis["first_appearance_timestamp"] is None:
                        keyword_analysis["first_appearance_timestamp"] = frame.timestamp_ms
                    
                    # å¼€å§‹è¿ç»­æœŸé—´
                    if not previous_found:
                        current_period_start = frame.timestamp_ms
                
                else:
                    # å…³é”®è¯æ¶ˆå¤±
                    if previous_found:
                        # è®°å½•ç¬¬ä¸€æ¬¡æ¶ˆå¤±
                        if keyword_analysis["first_disappearance_timestamp"] is None:
                            keyword_analysis["first_disappearance_timestamp"] = frame.timestamp_ms
                        
                        # ç»“æŸè¿ç»­æœŸé—´
                        if current_period_start is not None:
                            keyword_analysis["pattern_analysis"]["continuous_periods"].append({
                                "start_timestamp": current_period_start,
                                "end_timestamp": frame.timestamp_ms,
                                "duration_ms": frame.timestamp_ms - current_period_start
                            })
                            current_period_start = None
                
                previous_found = found_in_frame
            
            # å¤„ç†æœ€åä¸€ä¸ªè¿ç»­æœŸé—´
            if current_period_start is not None and frames_with_ocr:
                last_frame = frames_with_ocr[-1][0]
                keyword_analysis["pattern_analysis"]["continuous_periods"].append({
                    "start_timestamp": current_period_start,
                    "end_timestamp": last_frame.timestamp_ms,
                    "duration_ms": last_frame.timestamp_ms - current_period_start
                })
            
            analysis_results.append(keyword_analysis)
        
        return analysis_results
    
    async def analyze_video_keywords(self, video_id: int, request: KeywordAnalysisRequest, db: Session) -> dict:
        """åˆ†æè§†é¢‘ä¸­å…³é”®è¯çš„å‡ºç°å’Œæ¶ˆå¤±æ¨¡å¼"""
        # æ£€æŸ¥è§†é¢‘æ˜¯å¦å­˜åœ¨
        video = db.query(Video).filter(Video.id == video_id).first()
        if not video:
            raise HTTPException(status_code=404, detail="è§†é¢‘ä¸å­˜åœ¨")
        
        # æ£€æŸ¥æ˜¯å¦æœ‰OCRç»“æœ
        ocr_count = db.query(OCRResult).join(
            VideoFrame, OCRResult.frame_id == VideoFrame.id
        ).filter(
            VideoFrame.video_id == video_id
        ).count()
        
        if ocr_count == 0:
            raise HTTPException(status_code=404, detail="è§†é¢‘OCRç»“æœä¸å­˜åœ¨ï¼Œè¯·å…ˆè¿›è¡ŒOCRå¤„ç†")
        
        try:
            # æ‰§è¡Œå…³é”®è¯åˆ†æ
            analysis_results = self.analyze_keywords_in_ocr_results(video_id, request.keywords, db)
            
            return {
                "message": "å…³é”®è¯åˆ†æå®Œæˆ",
                "video_id": video_id,
                "analyzed_keywords": len(request.keywords),
                "analysis_results": analysis_results
            }
            
        except Exception as e:
            raise HTTPException(status_code=500, detail=f"å…³é”®è¯åˆ†æå¤±è´¥: {str(e)}")
    
    async def analyze_stage_keywords(self, video_id: int, db: Session) -> dict:
        """åŸºäºstage_configsåˆ†æå…³é”®è¯æ¨¡å¼"""
        # æ£€æŸ¥è§†é¢‘æ˜¯å¦å­˜åœ¨
        video = db.query(Video).filter(Video.id == video_id).first()
        if not video:
            raise HTTPException(status_code=404, detail="è§†é¢‘ä¸å­˜åœ¨")
        
        # è·å–è§†é¢‘çš„é˜¶æ®µé…ç½®
        stage_configs = db.query(StageConfig).filter(
            StageConfig.video_id == video_id
        ).order_by(StageConfig.stage_order).all()
        
        if not stage_configs:
            raise HTTPException(status_code=404, detail="è§†é¢‘é˜¶æ®µé…ç½®ä¸å­˜åœ¨")
        
        # æ£€æŸ¥æ˜¯å¦æœ‰OCRç»“æœ
        ocr_count = db.query(OCRResult).join(
            VideoFrame, OCRResult.frame_id == VideoFrame.id
        ).filter(
            VideoFrame.video_id == video_id
        ).count()
        
        if ocr_count == 0:
            raise HTTPException(status_code=404, detail="è§†é¢‘OCRç»“æœä¸å­˜åœ¨ï¼Œè¯·å…ˆè¿›è¡ŒOCRå¤„ç†")
        
        try:
            stage_analysis_results = []
            
            for config in stage_configs:
                # è§£æå…³é”®è¯
                keywords = json.loads(config.keywords) if isinstance(config.keywords, str) else config.keywords
                
                # åˆ†æå…³é”®è¯
                analysis_results = self.analyze_keywords_in_ocr_results(video_id, keywords, db)
                
                stage_analysis_results.append({
                    "stage_id": config.id,
                    "stage_name": config.stage_name,
                    "stage_order": config.stage_order,
                    "keywords": keywords,
                    "keyword_analysis": analysis_results
                })
            
            return {
                "message": "é˜¶æ®µå…³é”®è¯åˆ†æå®Œæˆ",
                "video_id": video_id,
                "total_stages": len(stage_configs),
                "stage_analysis_results": stage_analysis_results
            }
            
        except Exception as e:
            raise HTTPException(status_code=500, detail=f"é˜¶æ®µå…³é”®è¯åˆ†æå¤±è´¥: {str(e)}")
    
    async def analyze_keywords_by_stage_config(self, config_id: int, db: Session) -> dict:
        """åŸºäºé˜¶æ®µé…ç½®è¿›è¡Œå…³é”®è¯åˆ†æ"""
        try:
            # è·å–é˜¶æ®µé…ç½®
            stage_config = db.query(StageConfig).filter(StageConfig.id == config_id).first()
            if not stage_config:
                raise HTTPException(status_code=404, detail="é˜¶æ®µé…ç½®ä¸å­˜åœ¨")
            
            # è§£æå…³é”®è¯
            keywords = json.loads(stage_config.keywords) if isinstance(stage_config.keywords, str) else stage_config.keywords
            if not keywords:
                raise HTTPException(status_code=400, detail="é˜¶æ®µé…ç½®ä¸­æ²¡æœ‰å…³é”®è¯")
            
            # æ‰§è¡Œå…³é”®è¯åˆ†æ
            analysis_results = self.analyze_keywords_in_ocr_results(stage_config.video_id, keywords, db)
            
            return {
                "message": "åŸºäºé˜¶æ®µé…ç½®çš„å…³é”®è¯åˆ†æå®Œæˆ",
                "stage_config_id": config_id,
                "video_id": stage_config.video_id,
                "stage_name": stage_config.stage_name,
                "keywords_count": len(keywords),
                "analysis_results": analysis_results
            }
            
        except Exception as e:
            raise HTTPException(status_code=500, detail=f"å…³é”®è¯åˆ†æå¤±è´¥: {str(e)}")
    
    def delete_video_ocr_results(self, video_id: int, db: Session) -> dict:
        """åˆ é™¤è§†é¢‘çš„æ‰€æœ‰OCRç»“æœï¼ˆæ•°æ®åº“è®°å½•å’ŒJSONæ–‡ä»¶ï¼‰"""
        try:
            # æ£€æŸ¥è§†é¢‘æ˜¯å¦å­˜åœ¨
            video = db.query(Video).filter(Video.id == video_id).first()
            if not video:
                raise HTTPException(status_code=404, detail="è§†é¢‘ä¸å­˜åœ¨")
            
            # è·å–è§†é¢‘çš„æ‰€æœ‰å¸§
            frames = db.query(VideoFrame).filter(VideoFrame.video_id == video_id).all()
            
            deleted_db_records = 0
            deleted_json_files = 0
            
            # åˆ é™¤æ•°æ®åº“ä¸­çš„OCRè®°å½•
            for frame in frames:
                ocr_results = db.query(OCRResult).filter(OCRResult.frame_id == frame.id).all()
                for ocr_result in ocr_results:
                    db.delete(ocr_result)
                    deleted_db_records += 1
            
            # æäº¤æ•°æ®åº“æ›´æ”¹
            db.commit()
            
            # åˆ é™¤JSONæ–‡ä»¶
            ocr_output_dir = Path(f"{self.ocr_results_path}/video_{video_id}")
            if ocr_output_dir.exists():
                import shutil
                for json_file in ocr_output_dir.glob("*.json"):
                    try:
                        json_file.unlink()
                        deleted_json_files += 1
                    except Exception as e:
                        print(f"åˆ é™¤JSONæ–‡ä»¶å¤±è´¥: {json_file}, é”™è¯¯: {e}")
                
                # å¦‚æœç›®å½•ä¸ºç©ºï¼Œåˆ é™¤ç›®å½•
                try:
                    if not any(ocr_output_dir.iterdir()):
                        ocr_output_dir.rmdir()
                except Exception as e:
                    print(f"åˆ é™¤ç›®å½•å¤±è´¥: {ocr_output_dir}, é”™è¯¯: {e}")
            
            return {
                "message": "OCRç»“æœåˆ é™¤æˆåŠŸ",
                "video_id": video_id,
                "deleted_db_records": deleted_db_records,
                "deleted_json_files": deleted_json_files
            }
            
        except Exception as e:
            db.rollback()
            raise HTTPException(status_code=500, detail=f"åˆ é™¤OCRç»“æœå¤±è´¥: {str(e)}")
    
    def get_ocr_storage_info(self, video_id: int, db: Session) -> dict:
        """è·å–OCRç»“æœçš„å­˜å‚¨ä¿¡æ¯"""
        try:
            # æ£€æŸ¥è§†é¢‘æ˜¯å¦å­˜åœ¨
            video = db.query(Video).filter(Video.id == video_id).first()
            if not video:
                raise HTTPException(status_code=404, detail="è§†é¢‘ä¸å­˜åœ¨")
            
            # ç»Ÿè®¡æ•°æ®åº“ä¸­çš„OCRè®°å½•
            frames = db.query(VideoFrame).filter(VideoFrame.video_id == video_id).all()
            total_frames = len(frames)
            
            db_ocr_count = 0
            for frame in frames:
                ocr_count = db.query(OCRResult).filter(OCRResult.frame_id == frame.id).count()
                db_ocr_count += ocr_count
            
            # æ£€æŸ¥JSONæ–‡ä»¶å­˜å‚¨
            ocr_output_dir = Path(f"{self.ocr_results_path}/video_{video_id}")
            json_files = []
            total_json_size = 0
            
            if ocr_output_dir.exists():
                for json_file in ocr_output_dir.glob("*.json"):
                    file_size = json_file.stat().st_size
                    json_files.append({
                        "filename": json_file.name,
                        "size_bytes": file_size,
                        "size_kb": round(file_size / 1024, 2)
                    })
                    total_json_size += file_size
            
            return {
                "video_id": video_id,
                "database_info": {
                    "total_frames": total_frames,
                    "ocr_records_count": db_ocr_count
                },
                "json_storage_info": {
                    "storage_path": str(ocr_output_dir),
                    "json_files_count": len(json_files),
                    "total_size_bytes": total_json_size,
                    "total_size_kb": round(total_json_size / 1024, 2),
                    "files": json_files[:10]  # åªæ˜¾ç¤ºå‰10ä¸ªæ–‡ä»¶
                }
            }
            
        except Exception as e:
            raise HTTPException(status_code=500, detail=f"è·å–OCRå­˜å‚¨ä¿¡æ¯å¤±è´¥: {str(e)}")


# åˆ›å»ºå…¨å±€OCRå¤„ç†å™¨å®ä¾‹
ocr_processor = OCRProcessor()